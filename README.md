tinychad be a deep learning framework, not a good deep learning framework

it is gonna be slow, but its gonna be based

goals: 
  - write a compiler that compiles tinychad code into assmebly OR into something more based
  - recreate important deep learning architectures using tinychad (LSTM, RESNET, Transformer)

TODO: 
  - broadcasting rules for going backwards on unary ops (SUM, RESHAPE, MAX)
      ; need to double check this
  - MNIST


things to read: 
   - https://ai.stackexchange.com/questions/11643/how-should-i-implement-the-backward-pass-through-a-flatten-layer-of-a-cnn
          ; "unbroadcasting (unflattening) during backpropogation"


